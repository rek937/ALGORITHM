<!-- encoding = utf8 -->

#### Logistic Regression Model
和线性回归一样的，最终都要拟合一条直线解决分类问题。

sigmoid function:
$$
g(z) = \frac{1}{1 + e^{-z}}, 0 < g(z) < 1
$$

逻辑回归模型：
$$
f
$$

##### Decision Boundary：
选择sigmoid function作为逻辑回归模型，当配到数值为小数如何选择，设置一个阈值
f为0的时候，决策边界

##### Cost Function:
cost function:
$$
J
$$
loss function:
$$
L
$$
Simplified loss function:
$$
L
$$

##### Gredient descent:
最常见的梯度更新公式，偏导项的更新方式看起来和线性回归模型相似，因为只是改变了一个基础的模型底座，但是在自变量这些没有变化，在偏导的时候也不会发生变化。
$$
w_j
$$
$$
b
$$

<br />

#### Over Fitting
模型可以完全拟合训练集上面的所有点，无法完成预测任务。高偏差和高方差的模型都无法使用。
**增加训练集的规模**
**减少样本特征数量** 控制样本数量和样本规模的比例 手动或者算法选择对样本重要的特征
**Regularization**

<br />

#### Regularization
假设有cost function增加惩罚项之后：
$$
J
$$
这个会让选中的权重变得更小

正则化惩罚项加入cost function实现正则化代价函数：
$$
J
$$

##### 正则化线性回归：
根据正则化的cost function带入代价函数：
$$
J
$$
可以得到更新公式：
$$

$$

##### 正则化逻辑回归：
根据正则化的cost function带入代价函数：
$$
J
$$
可以得到更新公式：
$$

$$


